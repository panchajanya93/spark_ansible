---
 - name: Creating spark directory
   become: yes
   file:
     path: /usr/local/spark
     state: directory


 - name: Getting spark URL
   become: yes
   get_url:
       url: http://mirror.stjschools.org/public/apache/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz
       dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7.tgz

 - name: Extracting the spark file
   become: yes
   shell: tar -xvf spark-2.3.0-bin-hadoop2.7.tgz
   args:
     chdir: /usr/local/spark/

 - name: set spark path to SPARK_HOME 
   become: yes
   lineinfile:
      path: /home/panchu/.bashrc
      line: 'export SPARK_HOME=/usr/local/spark/spark-2.3.0-bin-hadoop2.7'

 - name: Export SPARK_HOME to bashrc
   become: yes
   lineinfile:
      path: /home/panchu/.bashrc
      line: 'export PATH=$PATH:$SPARK_HOME/bin'

 - name: sourcing .bashrc file
   become: yes
   shell: source ~/.bashrc
   args:
     chdir: /home/panchu



 - name: Adding spark master host
   become: yes
   lineinfile:
      path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh.template
      line: export SPARK_MASTER_HOST= "{{ groups['master_node'] }}"

 - name: Editing the file
   become: yes
   lineinfile:
     path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh.template
     line: export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk.x86_64

 - name: Add the port
   become: yes
   lineinfile:
     path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-defaults.conf.template
     line: spark.master spark://Master:7077



 - name: Remove localhost
   become: yes
   lineinfile:
     dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves.template
     regexp: "localhost"
     state: absent

 - name: create slaves file
   file:
     path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves
     state: touch


 - name: Edit the slaves file
   become: yes
   blockinfile:
     path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves
     block: |
        "{{ groups['slaves_node'] }}"
        
        
 - name: Variable registering through shell command
   shell: "echo $HOSTNAME"
   register: current_hostname

 - name: setting variable name
   set_fact:
   string_to_echo: "{{ current_hostname.stdout }}"

 - name: Start the master
   become: yes
   shell: start-master.sh
   args:
     chdir: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/sbin
   

 - name: Start the slave
   become: yes
   shell: start-slave.sh spark://{{ current_hostname.stdout }}:7077
   args:
      chdir: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/sbin


 - name: To check deamons on master and slaves started
   become: yes
   command: cd /usr/local/spark/spark-2.3.0-bin-hadoop2.7
   command: jps



