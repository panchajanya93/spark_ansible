---
 - name: Creating spark directory
   become: yes
   file:
     path: /usr/local/spark
     state: directory


 - name: Getting spark URL
   become: yes
   get_url:
       url: http://mirror.stjschools.org/public/apache/spark/spark-2.3.0/spark-2.3.0-bin-hadoop2.7.tgz
       dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7.tgz

 - name: Extracting the spark file
   become: yes
   shell: tar -xvf spark-2.3.0-bin-hadoop2.7.tgz
   args:
     chdir: /usr/local/spark/

 - name: set spark path 
   become: yes
   lineinfile:
      path: /home/panchu/.bashrc
      line: 'export PATH=$PATH:/usr/local/spark/bin'

 - name: sourcing .bashrc file
   become: yes
   shell: source ~/.bashrc
   args:
     chdir: /home/panchu


# - name: copying the file
#   become: yes
#   copy:
#     src: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh.template
#     dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh

 - name: Adding spark master host
   become: yes
   lineinfile:
      path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh.template
      line: export SPARK_MASTER_HOST="10.1.53.151"

 - name: Editing the file
   become: yes
   lineinfile:
     path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh.template
     line: export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk.x86_64

 - name: Add the port
   become: yes
   lineinfile:
     path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-defaults.conf.template
     line: spark.master spark://Master:7077


# - name: Copying the slave file
#   become: yes
#   copy:
#     src: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves.template
#     dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves

 - name: Remove localhost
   become: yes
   lineinfile:
     dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves.template
     regexp: "localhost"
     state: absent

 - name: create slaves file
   file:
     path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves
     state: touch


 - name: Edit the slaves file
   become: yes
   blockinfile:
     path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves
     block: |
        master
        slave


 - name: Start the master
   become: yes
   shell: start-master.sh
   args:
     chdir: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/sbin
   

 - name: Start the slave
   become: yes
   shell: start-slave.sh spark://spark-master.pj:7077
   args:
     chdir: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/sbin


 - name: To check deamons on master and slaves started
   become: yes
   command: cd /usr/local/spark/spark-2.3.0-bin-hadoop2.7
   command: jps



