---
 - name: copying the file
   become: yes
   copy:
      src: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh.template
      dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh


 - name: Editing the file
   become: yes
   lineinfile:
      path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-env.sh
      line: export SPARK_MASTER_HOST='172.31.47.109'
      line: export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk.x86_64

 - name: Add the port
   become: yes
   lineinfile:
      path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/spark-defaults.conf.template
      line: spark.master spark://Master:7077


 - name: Copying the slave file
   become: yes
   copy:
      src: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves.template
      dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves

 - name: Remove localhost
   become: yes
   lineinfile:
      dest: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves
      regexp: "localhost"
      state: absent


 - name: Edit the slaves file
   become: yes
   blockinfile:
      path: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/conf/slaves
      block: |
        Master
        Node


 - name: Start the master
   become: yes
   shell: start-master.sh
   args:
      chdir: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/sbin

 - name: Start the slave
   become: yes
   shell: start-slaves.sh
   args:
      chdir: /usr/local/spark/spark-2.3.0-bin-hadoop2.7/sbin


 - name: To check deamons on master and slaves started
   become: yes
   command: cd /usr/local/spark/spark-2.3.0-bin-hadoop2.7
   command: jps

